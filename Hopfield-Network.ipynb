{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fr1FQVuTDn19"
   },
   "source": [
    "# CPSC 585 - Artificial Neural Network\n",
    "## Spring 2021\n",
    "\n",
    "## Project 6 (Hopfield Network)\n",
    "\n",
    "## Malyaj Sirothia\n",
    "<br><br><br>\n",
    "\n",
    "\n",
    "**1. Use the contents of ratings.csv to create a dataset for your network. There should be a feature vector for each user, with each feature corresponding to a movie. Encode movies that the user has rated 3.0 or above as +1, and other movies as -1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId     movieId    rating     timestamp   \n",
      "1          1          4.0        964982703   \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ratings = pd.read_csv('ratings.csv', header=0,)\n",
    "userId = ratings['userId'][0]\n",
    "movieId = ratings['movieId'][0]\n",
    "rating = ratings['rating'][0]\n",
    "timestamp = ratings['timestamp'][0]\n",
    "\n",
    "print('%-10s %-10s %-10s %-12s' % ('userId', 'movieId', 'rating', 'timestamp'))\n",
    "print('%-10s %-10s %-10s %-12s' % (userId, movieId, rating, timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie id in unique movie ids:  3\n",
      "movie rindices:  [   0    2    5 ... 9444 9445 9485]\n",
      "length of movie_rindices:  100836\n",
      "dataset:  -1\n"
     ]
    }
   ],
   "source": [
    "# getting unique arrays and inverse-indices from ratings.csv\n",
    "movieIds = ratings['movieId']#.to_numpy()\n",
    "u_movie_ids, movie_rindices = np.unique(movieIds, return_inverse=True,)\n",
    "\n",
    "print('movie id in unique movie ids: ', u_movie_ids[2])\n",
    "print('movie rindices: ', movie_rindices) # dimension matches movieIds\n",
    "print('length of movie_rindices: ', len(movie_rindices))\n",
    "\n",
    "userIds = ratings['userId']\n",
    "u_user_ids, user_indices = np.unique(userIds, return_index=True,)\n",
    "i = 2\n",
    "\n",
    "# creating dataset\n",
    "dataset = np.ones((610, 9742,), dtype=int) * -1\n",
    "print('dataset: ', dataset[1,2])\n",
    "curr_user_id = ratings['userId'][0] # curr_user + 1 = userId\n",
    "\n",
    "movieIds = ratings['movieId']\n",
    "u_movie_ids, movie_rindices, occurrence_count = np.unique(movieIds, \n",
    "                                        return_counts=True, \n",
    "                                        return_inverse=True,)\n",
    "# u_movie_id has all the unique movieIds in the set, it is a mirror of feature vector\n",
    "# use movie_rindices and u_movie_ids to figure out which index in train_instance to flip to 1\n",
    "\n",
    "user_ids = ratings['userId']\n",
    "u_user_ids, user_indices = np.unique(userIds, return_index=True,)\n",
    "# user_indices - indices of first appearance of their userId\n",
    "# the difference between (user_indices[u], user_indices[u+1]) is how many movies they rated\n",
    "# print(user_indices)\n",
    "\n",
    "user_ratings = ratings['rating']\n",
    "for i in range(100836): # 100836 ratings\n",
    "    # use user_ids to check if we need to make a new train_instance\n",
    "    new_user_id = user_ids[i]\n",
    "    if new_user_id != curr_user_id:\n",
    "        curr_user_id = user_ids[i] \n",
    "    # use ratings to flip the feature bit to +1\n",
    "    if user_ratings[i] >= 3.0:\n",
    "        u_movie_rindex = movie_rindices[i]\n",
    "        dataset[curr_user_id-1][u_movie_rindex] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-BiGg7TDoGf"
   },
   "source": [
    "**2. Set aside 10% of your dataset for testing. How many users are there in the training set? What is the storage capacity of the network? Is the network likely to be able to store the dataset?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of test instances: 59\n",
      "number of training instances: 551\n"
     ]
    }
   ],
   "source": [
    "test_set_indices = np.random.randint(0, 610, 64)\n",
    "test_set_indices = np.unique(test_set_indices)\n",
    "dataset_indices = set([i for i in range(610)])\n",
    "train_set_indices = np.array(list(dataset_indices - set(test_set_indices)))\n",
    "print('number of test instances:',len(test_set_indices))\n",
    "print('number of training instances:', len(train_set_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wA2LjUfDoQe"
   },
   "source": [
    "**3.Construct a Hopfield network for your dataset and train it on your training set.\n",
    "Hint: You may want to take a look at the pseudocode on pp. 66-67 of Artificial Intelligence Engines.\n",
    "What accuracy does your trained network achieve?**\n",
    "\n",
    "The network reached an accuracy of **0.986** for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy based on number of features:  0.9863280253032783\n",
      "All or nothing accuracy: 0.10707803992740472\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check accuracy on the training set, RECALL\n",
    "# once finished training, plug in different instances of training set\n",
    "# accuracy - what percentage of recall and original vectors are similar\n",
    "\n",
    "W = np.zeros((9742, 9742), dtype=int)\n",
    "learning_rate = 1\n",
    "for i in train_set_indices:\n",
    "    x = dataset[i].reshape((9742, 1))\n",
    "    W_t = learning_rate * np.dot(x, x.T)\n",
    "    W = W + W_t\n",
    "\n",
    "# set diagonals to 0\n",
    "for i in range(9742):\n",
    "    W[i][i] = 0\n",
    "\n",
    "recall_correct = np.ones((610,1), dtype=int)\n",
    "\n",
    "\n",
    "incorrect_counts = []\n",
    "for v in train_set_indices:\n",
    "    num_incorrect = 0\n",
    "    x_prime = dataset[v]    # corrupted vector\n",
    "    y = np.array([i for i in x_prime])\n",
    "\n",
    "    stable = False\n",
    "    J = np.arange(0, 9742)\n",
    "    times = 0\n",
    "    while stable == False:\n",
    "        stable = True\n",
    "        np.random.shuffle(J)        \n",
    "        for k in range(9742):\n",
    "            j = J[k]\n",
    "            u_j = np.dot(W[j],y)    \n",
    "            y_last = y[j]\n",
    "            y[j] = 1 if u_j >= 0 else -1\n",
    "            if y[j] != y_last:\n",
    "                stable = False\n",
    "\n",
    "                        \n",
    "        times += 1\n",
    "        # end while\n",
    "\n",
    "    for i in range(9742):\n",
    "        if x_prime[i] != y[i]:\n",
    "            num_incorrect += 1\n",
    "            recall_correct[v] = False\n",
    "    incorrect_counts.append(num_incorrect)\n",
    "print('Accuracy based on number of features: ', 1 - np.sum(incorrect_counts) / 9742 / len(train_set_indices))\n",
    "print(f'All or nothing accuracy: {np.sum(recall_correct) / len(train_set_indices)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EylOTu0JDocT"
   },
   "source": [
    "**4. Determine your networkâ€™s accuracy on the test set. How well is the network performing?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9854935296758053\n"
     ]
    }
   ],
   "source": [
    "testset_incorrect_counts = []\n",
    "network_recalls = []   \n",
    "for v in test_set_indices:\n",
    "    x_prime = dataset[v]\n",
    "    y = np.array([i for i in x_prime])\n",
    "\n",
    "    stable = False\n",
    "    J = np.arange(0, 9742)\n",
    "\n",
    "    times = 0\n",
    "    while stable == False:\n",
    "        stable = True\n",
    "        np.random.shuffle(J)\n",
    "        for k in range(9742):\n",
    "            j = J[k]\n",
    "            u_j = np.dot(W[j],y)\n",
    "            y_last = y[j]\n",
    "            y[j] = 1 if u_j >= 0 else -1\n",
    "            if y[j] != y_last:\n",
    "                stable = False\n",
    "            \n",
    "        times += 1\n",
    "\n",
    "    num_incorrect = 0\n",
    "    for i in range(9742):\n",
    "        if x_prime[i] != y[i]:\n",
    "            num_incorrect += 1\n",
    "    testset_incorrect_counts.append(num_incorrect)\n",
    "    network_recalls.append((num_incorrect, v, y))\n",
    "\n",
    "print('accuracy: ', 1 - np.sum(testset_incorrect_counts) / 9742 / len(test_set_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iRatxlSDogR"
   },
   "source": [
    "**5. Choose a few higher-performing examples from the test set, then use movies.csv to determine which movies those users liked.\n",
    "Which other movies did the network predict that those users might like? Do the recommendations seem reasonable?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  0\n",
      "dataset:  [[ 1  1  1  1  1  1 -1  1 -1  1  1 -1  1  1 -1 -1  1  1 -1 -1]\n",
      " [-1  1  1  1 -1 -1  1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1  1]\n",
      " [-1 -1 -1 -1  1  1 -1 -1  1  1 -1 -1 -1  1  1  1  1 -1  1 -1]\n",
      " [-1  1  1 -1  1 -1 -1  1 -1  1 -1  1  1  1  1  1 -1 -1  1 -1]\n",
      " [-1 -1  1  1 -1 -1 -1  1  1  1 -1 -1  1 -1 -1 -1 -1  1  1 -1]]\n"
     ]
    }
   ],
   "source": [
    "dataset_observed = np.zeros((610, 9742,), dtype=int)\n",
    "dataset_random = np.random.randint(0,2, (610,9742)) * 2 - 1\n",
    "print('dataset: ', dataset_observed[1,2])\n",
    "curr_user_id = ratings['userId'][0] # curr_user + 1 = userId\n",
    "\n",
    "movieIds = ratings['movieId']\n",
    "u_movie_ids, movie_rindices, occurrence_count = np.unique(movieIds, \n",
    "                                        return_counts=True, \n",
    "                                        return_inverse=True,)\n",
    "\n",
    "user_ids = ratings['userId']\n",
    "u_user_ids, user_indices = np.unique(userIds, return_index=True,)\n",
    "\n",
    "user_ratings = ratings['rating']\n",
    "for i in range(100836): # 100836 ratings\n",
    "    new_user_id = user_ids[i]\n",
    "    if new_user_id != curr_user_id:\n",
    "        curr_user_id = user_ids[i] \n",
    "    if user_ratings[i] >= 3.0:\n",
    "        u_movie_rindex = movie_rindices[i]\n",
    "        dataset_observed[curr_user_id-1][u_movie_rindex] = 1\n",
    "        dataset_random[curr_user_id-1][u_movie_rindex] = 1\n",
    "    else: \n",
    "        dataset_observed[curr_user_id-1][u_movie_rindex] = -1\n",
    "        dataset_random[curr_user_id-1][u_movie_rindex] = -1\n",
    "\n",
    "print('dataset: ', dataset_random[:5, 50:70])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done testing!\n",
      "Testset incorrect count: [40, 130, 22, 354, 44, 173, 496, 94, 62, 182, 35, 350, 403, 24, 40, 15, 134, 137, 27, 261, 21, 32, 37, 90, 232, 366, 22, 30, 42, 15, 65, 57, 156, 223, 113, 20, 76, 49, 57, 81, 15, 12, 603, 248, 20, 158, 19, 49, 138, 486, 398, 163, 276, 69, 77, 45, 19, 180, 576]\n"
     ]
    }
   ],
   "source": [
    "testset_incorrect_counts = []\n",
    "network_recalls = []\n",
    "testset_correct_counts = []\n",
    "for v in test_set_indices:\n",
    "    x_prime = dataset_random[v]\n",
    "    y = np.array([i for i in x_prime])\n",
    "\n",
    "    stable = False\n",
    "    J = np.arange(0, 9742)\n",
    "\n",
    "    times = 0\n",
    "    while stable == False:\n",
    "        stable = True\n",
    "        np.random.shuffle(J)\n",
    "        for k in range(9742):\n",
    "            j = J[k]\n",
    "            u_j = np.dot(W[j],y)\n",
    "            y_last = y[j]\n",
    "            if not bool(dataset_observed[v][j]):    \n",
    "                y[j] = 1 if u_j >= 0 else -1\n",
    "            if y[j] != y_last:\n",
    "                stable = False\n",
    "            \n",
    "        times += 1\n",
    "\n",
    "    num_incorrect = 0\n",
    "    num_correct = 0\n",
    "    x = dataset[v]\n",
    "    x_observed = dataset_observed[v]\n",
    "    for i in range(9742):\n",
    "        if (x_observed[i] == 1 and y[i] == 1) or (x_observed[i] == -1 and y[i] == -1):\n",
    "            num_correct += 1\n",
    "    testset_incorrect_counts.append(num_incorrect)\n",
    "    network_recalls.append((num_incorrect, v, y))\n",
    "    testset_correct_counts.append(num_correct)\n",
    "\n",
    "print('Done testing!')\n",
    "print(f'Testset incorrect count: {testset_correct_counts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_ids in test_set where network has good performance:  [  4  51  59  61  68  73 110 114 164 165 175 218 225 235 237 244 246 264\n",
      " 276 289 298 299 315 321 324 356 362 378 397 405 416 426 427 431 436 438\n",
      " 446 449 457 459 466 477 482 483 517 526 530 531 551 554 560 569 572 578\n",
      " 583 587 594 604 607]\n",
      "\n",
      "user id - 1:  4 | incorrect_count: 0\n",
      "Index of user in network_recalls: 4\n",
      "Length of user_rated: 226\n",
      "indices of movies where user rated good: [   0    2    5   43   46   62   89   97  124  130  136  184  190  197\n",
      "  201  224  257  275  291  307  314  320  325  367  384  398  418  436\n",
      "  461  476  484  485  508  509  510  513  520  546  551  559  592  594\n",
      "  615  632  701  705  720  723  734  767  781  782  783  786  787  788\n",
      "  789  797  801  810  815  819  827  828  830  835  855  862  897  898\n",
      "  899  906  908  910  913  914  920  922  924  926  938  954  956  963\n",
      "  968  973  976  980  989  995 1035 1059 1075 1083 1109 1125 1145 1153\n",
      " 1170 1180 1182 1189 1217 1219 1223 1234 1260 1297 1318 1325 1331 1332\n",
      " 1400 1406 1430 1443 1474 1479 1486 1492 1502 1504 1515 1516 1521 1525\n",
      " 1542 1552 1555 1556 1558 1561 1566 1575 1576 1594 1596 1598 1600 1616\n",
      " 1627 1643 1686 1690 1703 1733 1754 1767 1787 1795 1805 1813 1825 1841\n",
      " 1849 1857 1865 1873 1882 1903 1904 1916 1938 1945 1956 1970 1978 1985\n",
      " 1986 1989 1990 1993 1996 2019 2027 2037 2076 2102 2125 2144 2156 2181\n",
      " 2192 2214 2216 2217 2218 2224 2246 2248 2252 2254 2257 2284 2285 2300\n",
      " 2301 2308 2370 2386 2429 2432 2438 2458 2523 2568 2569 2570 2576 2578\n",
      " 2599 2604 2632 2670 2692 2709 2729 2760 2761 2784 2794 2798 2832 2843\n",
      " 2987 3668]\n",
      "Number of movies network recommends:  37\n",
      "indices of movies where network rated good: [  0  20  32  33  35  46  52  97 123 126 198 211 217 225 251 257 277 302\n",
      " 314 322 355 398 412 413 450 461 464 467 506 507 508 509 511 512 513 514\n",
      " 520]\n",
      "Number of similarities: 9737\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_indices = []\n",
    "for val in np.unique(testset_incorrect_counts)[0:5]:\n",
    "    best_indices += list(np.where(testset_incorrect_counts == val)[0])\n",
    "print('user_ids in test_set where network has good performance: ', test_set_indices[best_indices])\n",
    "print()\n",
    "for i in best_indices[:1]:\n",
    "    print('user id - 1: ', test_set_indices[i], '| incorrect_count:', testset_incorrect_counts[i])\n",
    "    print(f'Index of user in network_recalls: {network_recalls[i][1]}')\n",
    "    user_rated = np.where(dataset[i] == 1)\n",
    "    print(f'Length of user_rated: {len(user_rated[0])}')\n",
    "        \n",
    "    print('indices of movies where user rated good:', user_rated[0])\n",
    "    network_rec = network_recalls[i][2]\n",
    "    network_rated = np.where(network_rec == 1)\n",
    "    print('Number of movies network recommends: ', len(network_rated[0]))\n",
    "    print('indices of movies where network rated good:', network_rated[0])\n",
    "\n",
    "    \n",
    "    user_index = network_recalls[i][1] \n",
    "    user_rated = dataset[user_index]\n",
    "    network_rated = network_recalls[i][2]\n",
    "\n",
    "    count = 0\n",
    "    for i in range(9742):\n",
    "        if user_rated[i] == network_rated[i]:\n",
    "            count += 1\n",
    "    print(f'Number of similarities: {count}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
